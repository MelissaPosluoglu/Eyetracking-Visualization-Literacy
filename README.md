# Mini-VLAT Eye-Tracking â€“ Visualization Literacy

Dieses Repository enthÃ¤lt den Analysecode fÃ¼r eine Eye-Tracking-Studie zur Untersuchung der Visualisierungskompetenz (Visualization Literacy) mithilfe des **Mini-VLAT-Tests**.  
Der Fokus liegt auf der zeitlich prÃ¤zisen Segmentierung einzelner Testfragen sowie auf der Analyse und Visualisierung von Fixationen auf stimulusbasierter Ebene.

---

## ğŸ“Œ Projektkontext

Das Projekt wurde im Rahmen eines universitÃ¤ren Forschungsprojekts durchgefÃ¼hrt und untersucht den Zusammenhang zwischen:

- Visualisierungskompetenz (Mini-VLAT)
- Blickverhalten (Eye Tracking)
- Zeitdruck und Aufgabenbearbeitung

Die Eye-Tracking-Daten wurden mit **Tobii** aufgezeichnet und als `.tsv` exportiert.  
Die Segmentierung der Aufgaben erfolgt anhand von **URL Start / URL End Events**, die wÃ¤hrend der webbasierten DurchfÃ¼hrung des Mini-VLAT-Tests geloggt wurden.

---

## ğŸ Python-Umgebung

Dieses Projekt verwendet **Python 3.11**.

### Voraussetzungen

- Python **3.11.x**
- Git
- Windows / macOS / Linux

---

## âš™ï¸ Setup (virtuelle Umgebung)

### 1ï¸âƒ£ Repository klonen

```bash
git clone https://github.com/MelissaPosluoglu/mini-vlat-eyetracking.git
cd mini-vlat-eyetracking
```

### 2ï¸âƒ£ Virtuelle Umgebung erstellen
```bash
python -m venv .venv
```

### 3ï¸âƒ£ Virtuelle Umgebung aktivieren

Windows (PowerShell):
```bash
.venv\Scripts\Activate.ps1
```

macOS / Linux:
```bash
source .venv/bin/activate
```

Nach der Aktivierung sollte im Terminal Folgendes erscheinen:
```
(.venv)
```

### 4ï¸âƒ£ AbhÃ¤ngigkeiten installieren

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ AusfÃ¼hren der Fixationsanalyse

Die Fixationsvisualisierung erzeugt fÃ¼r jede der 12 Mini-VLAT-Fragen eine eigene Abbildung, 
in der Fixationen Ã¼ber dem jeweiligen Stimulusbild dargestellt werden.

Skript starten
```bash
cd analysis
python fixation_all_questions.py
```


## ğŸ“Š Output

- FÃ¼r jede Frage wird ein Fixationsplot erzeugt
- Die Ergebnisse werden automatisch im Ordner `output_fixations/` gespeichert

Jede Abbildung zeigt:

- Fixationspositionen
- Fixationsdauer (PunktgrÃ¶ÃŸe)
- stimulus-spezifische Blickverteilung

---

## ğŸ§  Methodik (kurz)

- Die Segmentierung der Eye-Tracking-Daten erfolgt Ã¼ber **URL Start / URL End Events**
- Jede Fixation wird eindeutig einer Mini-VLAT-Frage zugeordnet
- Die Analyse erfolgt stimulusbasiert (eine Frage = ein Bild)
- Die Fixationsdauer wird visuell skaliert dargestellt

---

## ğŸ“„ Lizenz

Dieses Projekt steht unter der MIT License.
Eine freie Nutzung fÃ¼r Forschungs- und Lehrzwecke ist ausdrÃ¼cklich erlaubt.